{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'ibeatles_output.nxs.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = \"data/table.json\"\n",
    "assert os.path.exists(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_file, 'r') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['yaxis', 'xaxis', 'fitted', 'strain', 'd', 'a0', 'b0', 'ahkl', 'bhkl', 'tau', 'sigma', 'lambda_hkl', 'bragg peak threshold'])\n"
     ]
    }
   ],
   "source": [
    "os.remove(output_file_path)\n",
    "with h5py.File(output_file_path, 'w') as f:\n",
    "    entry = f.create_group('entry')\n",
    "\n",
    "    # fitting table\n",
    "    fitting_group = entry.create_group('fitting table')\n",
    "    for key in data.keys():\n",
    "\n",
    "        key_group = fitting_group.create_group(key)  \n",
    "        \n",
    "        _item1 = data[key]\n",
    "        key_group.create_dataset('xaxis', data=_item1['xaxis'])\n",
    "        key_group.create_dataset('yaxis', data=_item1['yaxis'])\n",
    "\n",
    "        fitted_group = key_group.create_group('fitted')\n",
    "        _item12 = _item1['fitted']\n",
    "\n",
    "        high_tof_group = fitted_group.create_group('hight_tof')\n",
    "        _item123 = _item12['high_tof']\n",
    "        high_tof_group.create_dataset('xaxis', data=_item123['xaxis'])\n",
    "        high_tof_group.create_dataset('yaxis', data=_item123['yaxis'])\n",
    "\n",
    "        low_tof_group = fitted_group.create_group('low_tof')\n",
    "        _item123 = _item12['low_tof']\n",
    "        low_tof_group.create_dataset('xaxis', data=_item123['xaxis'])\n",
    "        low_tof_group.create_dataset('yaxis', data=_item123['yaxis'])\n",
    "\n",
    "        bragg_peak_group = fitted_group.create_group('bragg_peak')           \n",
    "        _item123 = _item12['bragg_peak']\n",
    "        bragg_peak_group.create_dataset('xaxis', data=_item123['xaxis'])\n",
    "        bragg_peak_group.create_dataset('yaxis', data=_item123['yaxis'])\n",
    "\n",
    "        for _item in ['strain', 'd', 'a0', 'b0', 'ahkl', 'bhkl', 'tau', 'sigma', 'lambda_hkl']:\n",
    "            _group = fitted_group.create_group(_item)\n",
    "            _group.create_dataset('val', data=_item1[_item]['val'])\n",
    "            _group.create_dataset('err', data=_item1[_item]['err'])\n",
    "\n",
    "        bragg_peak_threshold = fitted_group.create_group('bragg peak threshold')\n",
    "        bragg_peak_threshold.create_dataset('left', data=_item1['bragg peak threshold']['left'])\n",
    "        bragg_peak_threshold.create_dataset('right', data=_item1['bragg peak threshold']['right'])\n",
    "\n",
    "\n",
    "            \n",
    "#     table_entry = entry.create_group('fitting_table')\n",
    "    \n",
    "#     for key in data.keys():\n",
    "#     table_json = table_entry.create_dataset(, data=data[key])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     daslogs = entry.create_group('daslogs')\n",
    "\n",
    "#     pv1 = daslogs.create_group('pv1')  \n",
    "#     dataset_1 = np.arange(1)\n",
    "#     data_mean = pv1.create_dataset('average_value', data=[np.mean(dataset_1)])\n",
    "#     data_min = pv1.create_dataset('maximum_value', data=[np.max(dataset_1)])\n",
    "#     data_max = pv1.create_dataset('minimum_value', data=[np.min(dataset_1)])\n",
    "#     data_set = pv1.create_dataset('value', data=dataset_1)\n",
    "    \n",
    "#     pv2 = daslogs.create_group('pv2')  \n",
    "#     dataset_2 = np.arange(10)\n",
    "#     data_mean = pv2.create_dataset('average_value', data=[np.mean(dataset_2)])\n",
    "#     data_min = pv2.create_dataset('maximum_value', data=[np.max(dataset_2)])\n",
    "#     data_max = pv2.create_dataset('minimum_value', data=[np.min(dataset_2)])\n",
    "#     data_set = pv2.create_dataset('value', data=dataset_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test hdf5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(output_file_path, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Group.visit of <HDF5 file \"ibeatles_output.nxs.h5\" (mode r)>>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
